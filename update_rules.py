import os
import re
import requests
from collections import defaultdict
from datetime import datetime
import hashlib

# 配置文件路径
CONFIG_FILE = 'rule_sources.conf'
OUTPUT_DIR = 'rule-provider'

def read_config(config_file):
    """读取配置文件并按类别分组 URL。"""
    categories = {}
    current_category = None
    
    with open(config_file, 'r') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
                
            if line.startswith('##'):
                current_category = line[2:].strip()
                categories[current_category] = []
            elif current_category and line.startswith('http'):
                categories[current_category].append(line)
    
    return categories

def download_rule(url):
    """从 URL 下载规则内容。"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        return response.text
    except Exception as e:
        print(f"下载 {url} 时出错: {e}")
        return None

def parse_rules(content):
    """从内容中解析规则。"""
    if not content:
        return {}
    
    # 规则类型计数器
    rule_types = {
        'DOMAIN': [],
        'DOMAIN-SUFFIX': [],
        'DOMAIN-KEYWORD': [],
        'IP-CIDR': [],
        'IP-ASN': [],
        'USER-AGENT': [],
        'URL-REGEX': [],
        'PROCESS-NAME': [],
        'TOTAL': 0
    }
    
    # 解析每一行
    for line in content.split('\n'):
        line = line.strip()
        if not line or line.startswith('#'):
            continue
        
        # 识别规则类型
        for rule_type in rule_types.keys():
            if rule_type != 'TOTAL' and line.startswith(rule_type):
                rule_types[rule_type].append(line)
                rule_types['TOTAL'] += 1
                break
    
    return rule_types

def merge_rules(sources, category_name):
    """合并来自多个源的规则。"""
    merged_rules = {
        'DOMAIN': set(),
        'DOMAIN-SUFFIX': set(),
        'DOMAIN-KEYWORD': set(),
        'IP-CIDR': set(),
        'IP-ASN': set(),
        'USER-AGENT': set(),
        'URL-REGEX': set(),
        'PROCESS-NAME': set()
    }
    
    # 下载并解析每个源的规则
    source_urls = []
    for url in sources:
        content = download_rule(url)
        if content:
            source_urls.append(url)
            rules = parse_rules(content)
            
            # 合并规则
            for rule_type, rule_list in rules.items():
                if rule_type != 'TOTAL':
                    for rule in rule_list:
                        merged_rules[rule_type].add(rule)
    
    # 生成输出文件内容
    output_content = []
    
    # 添加源 URL 作为注释
    for url in source_urls:
        output_content.append(f"# {url}")
    
    # 添加元数据
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    output_content.append(f"# NAME: {category_name}")
    output_content.append(f"# AUTHOR: Generated by GitHub Action")
    output_content.append(f"# REPO: https://github.com/your-username/your-repo")
    output_content.append(f"# UPDATED: {current_time}")
    
    # 添加规则类型计数
    total_rules = 0
    for rule_type, rules in merged_rules.items():
        if rules:
            output_content.append(f"# {rule_type}: {len(rules)}")
            total_rules += len(rules)
    
    output_content.append(f"# TOTAL: {total_rules}")
    
    # 添加规则
    for rule_type, rules in merged_rules.items():
        if rules:
            for rule in sorted(rules):
                output_content.append(rule)
    
    return "\n".join(output_content)

def main():
    """更新所有规则文件的主函数。"""
    # 确保输出目录存在
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # 读取配置
    categories = read_config(CONFIG_FILE)
    
    # 处理每个类别
    for category, urls in categories.items():
        print(f"正在处理 {category}...")
        merged_content = merge_rules(urls, category)
        
        # 写入输出文件
        output_file = os.path.join(OUTPUT_DIR, f"{category}.list")
        with open(output_file, 'w') as f:
            f.write(merged_content)
        
        print(f"已更新 {output_file}")

if __name__ == "__main__":
    main()
